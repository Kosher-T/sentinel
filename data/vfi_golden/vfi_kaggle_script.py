{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14102528,"sourceType":"datasetVersion","datasetId":8924809}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tqdm.notebook import tqdm  # specific for Kaggle/Jupyter progress bars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T05:31:47.481458Z","iopub.execute_input":"2025-12-11T05:31:47.481738Z","iopub.status.idle":"2025-12-11T05:31:47.486826Z","shell.execute_reply.started":"2025-12-11T05:31:47.481718Z","shell.execute_reply":"2025-12-11T05:31:47.485927Z"},"_kg_hide-input":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# --- 1. CONFIGURATION ---\n# Path to where your .keras files live\nMODEL_DIR = \"/kaggle/input/golden-set-vfi-model/vfi_golden\"\n\n# Path to the input images (im1.jpg, im3.jpg)\nINPUT_DATA_ROOT = \"/kaggle/input/golden-set-vfi-model/vfi_golden/golden_set_inputs\"\n\n# Where to save the results\nOUTPUT_ROOT = \"/kaggle/working/model_comparison_results\"\n\n# Image dimensions for the model\nMODEL_INPUT_SIZE = (256, 256)\n\n# --- 2. CUSTOM COMPONENTS (Required to load the models) ---\n\n@tf.keras.utils.register_keras_serializable(package=\"Custom\")\nclass SeparableKernelWarping(layers.Layer):\n    def __init__(self, kernel_size: int, **kwargs):\n        super().__init__(**kwargs)\n        self.kernel_size = kernel_size\n\n    def call(self, inputs):\n        I1, I3, kernels = inputs\n        B, H, W, C = tf.unstack(tf.shape(I1), num=4)\n        K = self.kernel_size\n\n        kernels_reshaped = tf.reshape(kernels, [B, H, W, 2, K, C])\n        K1 = kernels_reshaped[..., 0, :, :]\n        K3 = kernels_reshaped[..., 1, :, :]\n\n        ksizes_h = [1, 1, K, 1]\n        strides_h = [1, 1, 1, 1]\n        P1_H = tf.image.extract_patches(I1, sizes=ksizes_h, strides=strides_h, rates=[1, 1, 1, 1], padding=\"SAME\")\n        P3_H = tf.image.extract_patches(I3, sizes=ksizes_h, strides=strides_h, rates=[1, 1, 1, 1], padding=\"SAME\")\n        P1_H = tf.reshape(P1_H, [B, H, W, K, C])\n        P3_H = tf.reshape(P3_H, [B, H, W, K, C])\n\n        I1_warped_H = tf.einsum(\"bhwkc,bhwkc->bhwc\", P1_H, K1)\n        I3_warped_H = tf.einsum(\"bhwkc,bhwkc->bhwc\", P3_H, K3)\n        I_intermediate = I1_warped_H + I3_warped_H\n\n        ksizes_v = [1, K, 1, 1]\n        strides_v = [1, 1, 1, 1]\n        P_V = tf.image.extract_patches(I_intermediate, sizes=ksizes_v, strides=strides_v, rates=[1, 1, 1, 1], padding=\"SAME\")\n        P_V = tf.reshape(P_V, [B, H, W, K, C])\n        K_V = (K1 + K3) / 2.0\n        I_warped_V = tf.einsum(\"bhwkc,bhwkc->bhwc\", P_V, K_V)\n\n        return I_warped_V\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"kernel_size\": self.kernel_size})\n        return config\n\n@tf.keras.utils.register_keras_serializable(package=\"Custom\")\ndef ssim_loss(y_true, y_pred):\n    y_true = tf.clip_by_value(y_true, 0.0, 1.0)\n    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)\n    return 1.0 - tf.image.ssim(y_true, y_pred, max_val=1.0)\n\n@tf.keras.utils.register_keras_serializable(package=\"Custom\")\ndef total_loss(y_true, y_pred):\n    # These lambda values match your original training script\n    lambda_l1 = 0.8\n    lambda_ssim = 0.2\n    y_true = tf.clip_by_value(y_true, 0.0, 1.0)\n    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)\n    l1 = tf.reduce_mean(tf.abs(y_true - y_pred))\n    ssim = tf.reduce_mean(1.0 - tf.image.ssim(y_true, y_pred, max_val=1.0))\n    return (lambda_l1 * l1) + (lambda_ssim * ssim)\n\n@tf.keras.utils.register_keras_serializable(package=\"Custom\")\ndef psnr_metric(y_true, y_pred):\n    y_true = tf.clip_by_value(y_true, 0.0, 1.0)\n    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)\n    val = tf.image.psnr(y_true, y_pred, max_val=1.0)\n    return tf.where(tf.math.is_inf(val), 100.0, val)\n\n# --- 3. HELPER FUNCTIONS ---\n\ndef preprocess_image(image_path, target_size):\n    img = cv2.imread(image_path)\n    if img is None:\n        return None, None\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    original_h, original_w = img.shape[:2]\n    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n    img_normalized = img_resized.astype(np.float32) / 255.0\n    img_batch = np.expand_dims(img_normalized, axis=0)\n    return img_batch, (original_h, original_w)\n\ndef run_inference(model, im1_path, im3_path):\n    im1_batch, orig_dims = preprocess_image(im1_path, MODEL_INPUT_SIZE)\n    im3_batch, _ = preprocess_image(im3_path, MODEL_INPUT_SIZE)\n    \n    if im1_batch is None or im3_batch is None:\n        return None\n\n    inputs = np.concatenate([im1_batch, im3_batch], axis=-1)\n    prediction = model.predict(inputs, verbose=0)\n    \n    gen_img = np.clip(prediction[0], 0.0, 1.0)\n    \n    # Upscale back to original resolution using cubic interpolation\n    gen_img_upscaled = cv2.resize(gen_img, (orig_dims[1], orig_dims[0]), interpolation=cv2.INTER_CUBIC)\n    gen_img_uint8 = (gen_img_upscaled * 255.0).astype(np.uint8)\n    return gen_img_uint8\n\n# --- 4. MAIN EXECUTION LOOP ---\n\ndef main():\n    # 1. Find all .keras models\n    model_files = sorted(glob.glob(os.path.join(MODEL_DIR, \"*.keras\")))\n    print(f\"Found {len(model_files)} models to evaluate.\")\n\n    # 2. Find all input samples\n    # Assuming input structure: .../golden_set_inputs/sample_001/im1.jpg\n    sample_folders = sorted(glob.glob(os.path.join(INPUT_DATA_ROOT, \"*\")))\n    print(f\"Found {len(sample_folders)} sample inputs.\")\n\n    # 3. Iterate through every model\n    for model_path in tqdm(model_files, desc=\"Evaluated Models\"):\n        model_filename = os.path.basename(model_path)\n        # Create a clean folder name, e.g., \"vfi_epoch_20\"\n        model_name_safe = os.path.splitext(model_filename)[0]\n        \n        print(f\"\\nLoading Model: {model_name_safe}...\")\n        \n        # Load the model with custom objects\n        try:\n            model = tf.keras.models.load_model(\n                model_path, \n                custom_objects={\n                    'SeparableKernelWarping': SeparableKernelWarping,\n                    'total_loss': total_loss,\n                    'psnr_metric': psnr_metric,\n                    'ssim_loss': ssim_loss,\n                }\n            )\n        except Exception as e:\n            print(f\"‚ùå Failed to load {model_filename}: {e}\")\n            continue\n\n        # Create output directory for this specific model\n        model_output_dir = os.path.join(OUTPUT_ROOT, model_name_safe)\n        os.makedirs(model_output_dir, exist_ok=True)\n\n        # Process all samples for this model\n        for folder in sample_folders:\n            folder_name = os.path.basename(folder)\n            im1_path = os.path.join(folder, \"im1.jpg\")\n            im3_path = os.path.join(folder, \"im3.jpg\")\n\n            # Create subdirectory for the sample (e.g., Results/vfi_epoch_20/sample_001)\n            sample_out_dir = os.path.join(model_output_dir, folder_name)\n            os.makedirs(sample_out_dir, exist_ok=True)\n\n            # Generate frame\n            result_frame = run_inference(model, im1_path, im3_path)\n            \n            if result_frame is not None:\n                # Save result (convert RGB back to BGR for OpenCV)\n                save_path = os.path.join(sample_out_dir, \"im2_pred.jpg\")\n                cv2.imwrite(save_path, cv2.cvtColor(result_frame, cv2.COLOR_RGB2BGR))\n                \n                # Copy inputs too, so you don't have to look elsewhere to compare\n                shutil.copy(im1_path, os.path.join(sample_out_dir, \"im1.jpg\"))\n                shutil.copy(im3_path, os.path.join(sample_out_dir, \"im3.jpg\"))\n            else:\n                print(f\"Skipping {folder_name} (missing images)\")\n\n        # CRITICAL: Clear memory so Kaggle doesn't crash on the next loop\n        del model\n        tf.keras.backend.clear_session()\n        print(f\"‚úÖ {model_name_safe} complete. Memory cleared.\")\n\n    print(f\"\\nüéâ All models processed! Results saved in: {OUTPUT_ROOT}\")\n    print(\"You can now zip the 'model_comparison_results' folder and download it.\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T05:31:51.033956Z","iopub.execute_input":"2025-12-11T05:31:51.034672Z"}},"outputs":[{"name":"stdout","text":"üîé Found 14 models to evaluate.\nüìÇ Found 56 sample inputs.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluated Models:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ffa93a5da3640fca07466e955c40de9"}},"metadata":{}},{"name":"stdout","text":"\nüöÄ Loading Model: vfi_epoch_20...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1765431111.936345      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1765431111.937030      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nI0000 00:00:1765431113.883741     112 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ vfi_epoch_20 complete. Memory cleared.\n\nüöÄ Loading Model: vfi_epoch_25...\n‚úÖ vfi_epoch_25 complete. Memory cleared.\n\nüöÄ Loading Model: vfi_epoch_30...\n‚úÖ vfi_epoch_30 complete. Memory cleared.\n\nüöÄ Loading Model: vfi_epoch_35...\n‚úÖ vfi_epoch_35 complete. Memory cleared.\n\nüöÄ Loading Model: vfi_epoch_40...\n‚úÖ vfi_epoch_40 complete. Memory cleared.\n\nüöÄ Loading Model: vfi_epoch_45...\n‚úÖ vfi_epoch_45 complete. Memory cleared.\n\nüöÄ Loading Model: vfi_epoch_50...\n","output_type":"stream"}],"execution_count":null}]}